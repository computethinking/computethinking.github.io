{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"genai/","title":"Computational Thinking &amp; Generative AI","text":""},{"location":"genai/#the-power-of-text-and-llms","title":"The Power of Text and LLMs","text":"<p>When you think of \"computation\" or \"programming,\" what comes to mind? Perhaps you envision a software engineer writing complex code, a data analyst crunching numbers in a spreadsheet, or a mobile app developer creating the next viral game. These are all valid examples of traditional computation, where explicit instructions are written to perform specific tasks. On the other hand, text generation might evoke images of automated email responses, simple chatbots, or perhaps even grammar and spell-check tools.  These applications, while useful, often involve predefined templates or rule-based systems with limited flexibility. But the true power of text generation lies in its ability to tackle complex, nuanced tasks that were once thought to be exclusive to human intelligence. Consider these examples:</p> <ul> <li>Creative Work: Imagine generating compelling marketing copy for a new product. An AI assistant could analyze product features, target audience demographics, and even competitor messaging to craft original and persuasive content.</li> <li>Analytical Work:  Instead of manually sifting through mountains of data, an AI could analyze reports, summarize key findings, and even extract insights from unstructured data like meeting transcripts and emails.</li> <li>Automation Work:  AI-powered chatbots can provide instant, personalized customer support, analyze technical issues, and guide users to relevant solutions, all while communicating in a natural and engaging manner.</li> </ul> <p>Large Language Models (LLMs) are driving this revolution. They can generate human-quality text, translate languages, write different kinds of creative content, and answer your questions in an informative way,  all through simple prompts written in natural language.  This allows for creating ad-hoc solutions to complex business problems on demand, without the need for specialized programming or data science expertise.</p> <p>However, crafting effective prompts that can elicit the desired output from an LLM requires more than just asking a question. It involves applying the principles of computational thinking:</p> <ul> <li>Decomposition: Breaking down a complex problem into smaller, more manageable sub-problems that the LLM can address.</li> <li>Abstraction:  Focusing on the essential information and desired outcome, while avoiding unnecessary details that might confuse the model.</li> <li>Algorithmic Thinking:  Structuring the prompt in a logical and sequential manner, providing clear instructions and constraints.</li> <li>Pattern Recognition:  Understanding the patterns and nuances of language to craft prompts that resonate with the LLM's training data and elicit the most relevant and accurate responses.</li> </ul>"},{"location":"genai/#understanding-large-language-models-llms","title":"Understanding Large Language Models (LLMs)","text":"<p>2.1 What are LLMs?</p> <p>Large Language Models (LLMs) are sophisticated AI systems that can understand and generate human-like text.  They are built upon neural networks, which are complex structures inspired by the human brain. These networks consist of interconnected nodes, processing and transmitting information like neurons.</p> <p>Imagine each node as a tiny decision-maker,  collectively contributing to the model's ability to understand and generate language.</p> <p>2.2  Key Characteristics of LLMs</p> <p>To effectively leverage LLMs, it's important to understand some of their key characteristics:</p> <ul> <li>Training Data: LLMs are trained on massive datasets of text and code, which influences their capabilities and potential biases.</li> <li>Architecture: The arrangement of these interconnected nodes in layers affects the model's performance and efficiency. Information flows through these layers, allowing the model to process and generate text.</li> <li>Parameters:  Think of parameters as the knobs and dials that control the model's behavior. A simple linear model might need only two parameters to describe a relationship. But human language is vastly more complex, requiring millions or even billions of parameters for LLMs to capture its nuances. For instance, ChatGPT boasts 175 billion parameters, while Gemini has even more!</li> <li>Capabilities: LLMs demonstrate remarkable capabilities, including:<ul> <li>Text generation:  Writing stories, poems, articles, and even code.</li> <li>Translation:  Accurately translating between multiple languages.</li> <li>Summarization:  Condensing lengthy documents into concise summaries.</li> <li>Question answering:  Providing informative and comprehensive answers to complex questions.</li> </ul> </li> </ul> <p>It's important to note that while some LLMs may excel in multiple areas, trade-offs often exist. A model optimized for creative writing might not be the best at factual summarization. Additionally, LLMs can sometimes \"hallucinate,\" generating incorrect or nonsensical information, highlighting the need for careful evaluation and critical thinking when using these models.</p> <p>2.3 Understanding Model Cards</p> <p>Now that you have a basic understanding of LLMs, let's explore how companies actually access and utilize these powerful models.</p> <p>Accessing LLMs</p> <p>There are several ways for businesses to get started with LLMs:</p> <ul> <li>Public Cloud Providers: Companies like Google, Microsoft, and Amazon offer LLMs as a service through their cloud platforms. This allows businesses to access and use these models without the need for significant infrastructure investments.</li> <li>Model Repositories: Platforms like Hugging Face and Google's Vertex AI Model Garden provide access to a wide range of pre-trained LLMs, often with different capabilities and specializations.</li> <li>Web Services/Subscriptions: Many LLMs are accessible via web services or APIs (Application Programming Interfaces). This allows developers to integrate these models into their own applications or workflows using simple REST (Representational State Transfer) commands.</li> <li>Self-Hosting: For companies with specific security or privacy requirements, self-hosting LLMs in their own data centers is also an option, although it requires significant infrastructure and expertise.</li> </ul> <p>The Need for Model Cards</p> <p>With so many LLMs available, choosing the right one for a specific task can be challenging. This is where model cards play a crucial role.</p> <p>To help users choose the right LLM for their needs, model developers provide model cards. These cards provide essential information about the model, including:</p> <ul> <li>Training data:  What kind of data was the model trained on?</li> <li>Intended use cases: What tasks is the model best suited for?</li> <li>Limitations: What are the model's limitations or potential biases?</li> <li>Ethical considerations: Are there any ethical implications to consider when using the model?</li> <li>Performance metrics: How well does the model perform on different tasks?</li> </ul> <p>By understanding the information presented in a model card, you can evaluate an LLM's fitness-for-purpose and make informed decisions about its suitability for your specific business needs.</p> <p>Check out model cards from Hugging Face for OpenAI, Google, and Meta below.</p> <p>Open AI Google Meta</p> <p>2.4  Beyond the Basics</p> <p>While this provides a high-level overview, there are many other aspects to LLMs, such as:</p> <ul> <li>Fine-tuning: Adapting a pre-trained LLM for specific tasks or domains.</li> <li>Prompt engineering: Crafting effective prompts to elicit desired outputs.</li> <li>Model evaluation:  Assessing the performance and limitations of different LLMs.</li> </ul>"},{"location":"genai/#prompt-design-as-computational-thinking","title":"Prompt Design as Computational Thinking","text":"<p>2.1 Introduction to Prompts</p> <p>In traditional computing, we use programming languages to communicate with computers. We write explicit instructions, defining the exact steps and logic for the computer to execute. Whether it's automating office tasks or building complex software, our ability to express solutions through code is crucial.</p> <pre><code>def calculate_area(length: float, width: float) -&gt; float:\n  \"\"\"Calculates the area of a rectangle.\n\n  Args:\n    length: The length of the rectangle.\n    width: The width of the rectangle.\n\n  Returns:\n    The area of the rectangle.\n  \"\"\"\n  return length * width\n</code></pre> <p>For example, this Python function calculates the area of a rectangle. Its type signature (<code>calculate_area(length: float, width: float) -&gt; float</code>) defines how we can interact with it, while the code within its body represents the logic it executes.</p> <p>Generative AI, however, offers a different paradigm. Instead of rigid programming syntax, we use natural language to communicate with Large Language Models (LLMs).  These models have learned from vast amounts of text data, encoding knowledge and patterns that allow them to understand and respond to human language.</p> <p>Think of an LLM as a knowledgeable assistant who understands your instructions, can access and process information relevant to your request, and can generate outputs that meet your specific needs.</p> <p>Crafting Effective Prompts</p> <p>To effectively utilize LLMs, we need to craft prompts that clearly convey our intent.  This involves:</p> <ul> <li>Instructions:  Clearly stating what we want the LLM to do.  For example, \"Summarize this article\" or \"Write a poem about nature.\"</li> <li>Context: Providing relevant information that helps the LLM understand the task and generate a more accurate response.  For instance, if you're asking for marketing copy, provide details about the product and target audience.</li> <li>Constraints: Specifying any limitations or requirements for the output. This could include the desired length, format, or style.</li> </ul> <p>Beyond Explicit Instructions</p> <p>Interestingly, LLMs can also infer instructions and processing logic from various cues:</p> <ol> <li>Examples: Providing one or more examples of the desired output can guide the LLM's generation process. This is akin to showing, rather than just telling, the model what you want.</li> <li>Persona or Scenario: Asking the LLM to adopt a specific persona (e.g., \"Imagine you are a financial advisor\") or assume a scenario can influence its response and generate more contextually relevant output.</li> <li>Memory: LLMs have a form of memory, allowing them to retain and contextualize information from recent interactions. This means that the model's response to a current prompt can be influenced by previous prompts and responses within the same conversation. This allows for more dynamic and engaging interactions.</li> </ol>"},{"location":"genai/#anatomy-of-a-prompt","title":"Anatomy of a Prompt","text":"<p>3.1 Required vs. Optional Elements</p> <p>Crafting effective prompts is like assembling a puzzle. You need the right pieces in the right places to create a complete and meaningful picture. Here's a breakdown of the essential and optional components of a prompt:</p> <ul> <li> <p>Required:</p> <ul> <li>Task: Clearly state what you want the LLM to do. This is the core of your prompt, like the centerpiece of a puzzle. Think of verbs like \"summarize,\" \"translate,\" \"write,\" \"analyze,\" or \"generate.\"</li> <li>Content:  Provide the information that the LLM should work with. This could be a text passage, a set of data points, a question, or even a creative idea.</li> </ul> </li> <li> <p>Optional:</p> <ul> <li>Instructions:  Provide additional guidance on how the LLM should perform the task. Think of adverbs and adjectives that add detail and specificity: \"summarize concisely,\" \"translate accurately,\" \"write in a humorous tone.\"</li> <li>Context:  Include relevant background information to help the LLM understand the task and generate a more accurate response. This is like providing the LLM with the edges of the puzzle, helping it see the bigger picture.</li> <li>Constraints:  Specify any limitations or requirements for the output. This could include the desired length, format, or style. Constraints are like the boundaries of the puzzle, keeping the LLM focused on the desired outcome.</li> </ul> </li> </ul> <p>3.2 System Instructions</p> <p>System instructions are special directives that guide the LLM's overall behavior. Think of them as setting the ground rules for the AI, influencing its approach to every task and interaction.  They are crucial for implementing your organization's policies regarding privacy, AI safety, and security.</p> <p>Here's how system instructions can help:</p> <ul> <li>Guiding Principles: Clearly state your company's policies regarding data privacy, responsible AI usage, and security protocols. For example, \"You will prioritize user privacy and will not disclose any personally identifiable information.\"</li> <li>Setting Boundaries: Define explicit constraints on the AI's responses.  This might include preventing the generation of harmful, biased, or inappropriate content. For instance, \"You will not generate responses that are racist, sexist, or discriminatory in any way.\"</li> <li>Enforcing Compliance: Ensure the AI adheres to legal and ethical guidelines. This could involve respecting copyright laws, avoiding plagiarism, or providing accurate information.</li> </ul> <p>While system instructions are a powerful tool, they are not a silver bullet.  A comprehensive approach to safety and compliance requires a multi-layered strategy.</p> Beyond System Instructions: A Multi-layered Approach to Safety and Compliance <p>While system instructions are essential, they are just one piece of the puzzle. To build truly safe and compliant AI solutions, consider these additional measures:</p> <p>Data Security:</p> <ul> <li>Input Sanitization:  Remove or mask sensitive information from user inputs.</li> <li>Output Filtering:  Prevent the AI from generating harmful or sensitive outputs.</li> <li>Data Encryption:  Protect data during transmission and storage.</li> <li>Access Control:  Restrict access to the AI and its data.</li> </ul> <p>Model Selection and Fine-tuning:</p> <ul> <li>Choose responsible models: Prioritize models trained on diverse and unbiased data.</li> <li>Fine-tune for safety:  Adapt the model to align with your specific policies.</li> </ul> <p>Monitoring and Auditing:</p> <ul> <li>Continuous Monitoring:  Track AI interactions and outputs for potential issues.</li> <li>Regular Audits:  Assess the effectiveness of your safety measures.</li> </ul> <p>User Education:</p> <ul> <li>Transparency:  Inform users about the AI's capabilities and limitations.</li> <li>Guidance:  Provide clear instructions on responsible AI interaction.</li> </ul> <p>Red Teaming:</p> <ul> <li>Adversarial Testing:  Proactively identify vulnerabilities through simulated attacks.</li> </ul> <p>3.3 Chat vs. Completion</p> <p>LLMs can operate in two primary modes: chat and completion. Understanding the distinctions between these modes is crucial for selecting the right approach for your application.</p> <ul> <li> <p>Chat Mode: This mode facilitates an ongoing conversation where the LLM retains context from previous interactions. Think of it like a conversation with a colleague, where your current exchange builds upon what was said earlier. This is ideal for scenarios where:</p> <ul> <li>Context is crucial: The LLM needs to understand the flow of the conversation and maintain information from previous turns.</li> <li>Dynamic interaction is needed:  The user's input might evolve or change based on the LLM's responses, requiring a back-and-forth exchange.</li> <li>Longer conversations are desired:  The interaction involves a series of prompts and responses, potentially exceeding the context window of a single completion request.</li> </ul> </li> <li> <p>Completion Mode: This mode involves providing a single prompt and receiving a single response, without any conversational context. It's like sending a self-contained email or text message. This is suitable for:</p> <ul> <li>Self-contained tasks: The prompt provides all the necessary context and instructions, and a single response is sufficient.</li> <li>Limited or irrelevant context: The interaction doesn't require the LLM to retain information from previous turns.</li> <li>Efficiency: Completion mode can be faster and less computationally expensive for simple tasks.</li> </ul> </li> </ul> <p>Relationship between Chat and Completion</p> <p>You can think of chat mode as a generalization of completion mode. A completion task can be seen as a special case of a chat interaction where the conversation length is limited to a single turn.</p> <p>Key Considerations:</p> <ul> <li>Context Window:  In chat mode, managing the context window becomes crucial as the conversation progresses. Techniques like summarization or context window extension might be necessary to maintain coherence over extended interactions.</li> <li>Prompt Design:  In chat mode, prompts need to be designed with the ongoing conversation in mind. Each prompt should build upon the previous interactions and provide sufficient context for the LLM to understand the user's intent.</li> <li>Application Design:  The choice between chat and completion modes significantly influences the design of the user interface and the overall user experience.</li> </ul> <p>By carefully considering these factors, you can choose the most appropriate mode for your specific application and leverage the strengths of LLMs effectively.</p> <p>3.4 Tokens and Context Window</p> <p>Large Language Models (LLMs) don't process text as a continuous stream of words. Instead, they break it down into smaller units called tokens. A token can be a word, a part of a word, or even a punctuation mark. Think of them as the individual building blocks of language that the LLM understands and manipulates.</p> <p>The context window refers to the maximum number of tokens the LLM can consider at a time. It's like the model's short-term memory, limiting how much information it can hold and process simultaneously. This limitation applies even when dealing with multimodal prompts, where images and other modalities are also converted into tokens, potentially consuming a significant portion of the context window.</p> <p>Exceeding the context window can lead to truncated or irrelevant responses, as the LLM might lose track of earlier parts of the conversation or prompt. This is particularly crucial in chat-based interactions, where the conversation history can quickly fill up the context window.</p> <p>To address these limitations, developers employ various techniques:</p> <ul> <li>Prompt Caching: Storing previous prompts and responses to reuse or adapt them for similar interactions.</li> <li>Summarization: Condensing the conversation history to maintain context while reducing the number of tokens.</li> <li>Context Window Extension Techniques: Employing methods like sliding windows, attention mechanisms, and memory networks to effectively extend the context window.</li> <li>Hybrid Approaches: Combining these techniques to optimize performance and maintain context.</li> <li>Prompt Engineering: Encouraging concise prompts and breaking down complex tasks into smaller sub-tasks.</li> </ul> <p>Understanding the concept of context window is crucial for crafting effective prompts and designing successful LLM applications. By being mindful of its limitations and employing appropriate strategies, you can ensure that your interactions with LLMs remain coherent, relevant, and productive.</p> <p>3.5 Controlling Output with Generation Parameters</p> <p>In addition to the core elements of a prompt, you can further refine the LLM's output using generation parameters. These parameters act as \"knobs\" that you can adjust to influence the generation process. Some common parameters include:</p> <ul> <li>Temperature: This parameter controls the \"creativity\" or randomness of the LLM's output. Higher temperatures result in more diverse and unexpected outputs, while lower temperatures produce more focused and deterministic responses.</li> <li>Top-K: This parameter limits the LLM's choices to the top K most probable tokens at each step. This can be used to control the diversity and predictability of the output.</li> </ul> <p>By experimenting with these parameters, you can fine-tune the LLM's responses to better align with your specific needs and preferences.</p> <p>3.6 Prompt Formatting, Length, and Common Pitfalls</p> <p>To get the most out of your interactions with LLMs, it's important to pay attention to not just the content of your prompts but also their structure and presentation.</p> <p>Prompt Formatting</p> <p>Think of prompt formatting as the grammar and punctuation of your instructions to the LLM.  While LLMs are generally robust to minor variations, following these guidelines can improve clarity and effectiveness:</p> <ul> <li>Whitespace: Use whitespace effectively to separate different parts of your prompt, such as instructions, context, and the main content. This improves readability for both you and the LLM.</li> <li>Punctuation: Use correct punctuation to ensure the LLM understands the structure and intent of your prompt. For example, use periods to end sentences, commas to separate items in a list, and quotation marks to denote direct speech or citations.</li> <li>Special Characters:  Some LLMs might interpret special characters or markdown formatting in specific ways. Be aware of these conventions and use them consistently to structure your prompts.</li> </ul> <p>Prompt Length</p> <p>Remember that LLMs have a limited context window, which determines how much information they can process at a time.  Keep your prompts concise and focused, avoiding unnecessary details or repetition. If you need to provide a lot of context, consider breaking it down into smaller chunks or using summarization techniques.</p> <p>Common Pitfalls</p> <p>Here are some common pitfalls to avoid when crafting prompts:</p> <ul> <li>Vague Instructions:  Avoid ambiguous or unclear instructions. Be specific about what you want the LLM to do.</li> <li>Irrelevant Context:  Don't overload the prompt with unnecessary information. Focus on the context that is directly relevant to the task.</li> <li>Overly Restrictive Constraints:  While constraints can be helpful, avoid making them too rigid. Allow the LLM some flexibility to generate creative and insightful responses.</li> <li>Ignoring Model Capabilities:  Choose an LLM that is suitable for the task at hand. Don't expect a model specialized in summarization to excel at creative writing.</li> <li>Neglecting Ethical Considerations:  Be mindful of the potential biases and ethical implications of LLMs. Avoid generating harmful or misleading content.</li> </ul> <p>By paying attention to these aspects of prompt design, you can significantly improve the quality and relevance of the LLM's outputs.</p> <p>Okay, I can help you develop this section, incorporating the comparison with the Gemini app and omitting the subsection on the <code>requests</code> library as you requested.</p>"},{"location":"genai/#hands-on-with-google-ai-studio-and-gemini","title":"Hands-on with Google AI Studio and Gemini","text":"<p>3.1 Introducing Google AI Studio</p> <p>Now that we've explored the concepts of prompts and prompt design, it's time to get hands-on! Google AI Studio provides a user-friendly platform for accessing and experimenting with various generative AI models, including Gemini.</p> <p></p> <p>Think of AI Studio as your creative playground for exploring the capabilities of LLMs. It offers several benefits:</p> <ul> <li>Ease of Use: AI Studio provides a streamlined interface that simplifies interacting with LLMs, even without coding experience.</li> <li>Model Exploration: You can easily access and experiment with different LLMs, comparing their strengths and weaknesses for various tasks.</li> <li>Prompt Experimentation: The platform allows you to iterate on your prompts, trying different variations and observing their impact on the generated output.</li> <li>Collaboration: You can share your prompts and results with others, fostering collaboration and knowledge sharing.</li> </ul> <p>AI Studio vs. Gemini App</p> <p>You might be wondering how AI Studio differs from the Gemini app. While both provide access to Gemini, they cater to different needs and use cases:</p> <ul> <li>AI Studio: Focuses on providing a flexible and customizable environment for experimenting with various LLMs, including Gemini. It offers more advanced features and allows for programmatic access through APIs.</li> <li>Gemini App: Provides a more streamlined and user-friendly experience for casual users who want to explore Gemini's capabilities without delving into technical details.</li> </ul> <p>3.2 Introducing Gemini</p> <p>Gemini is Google's next-generation family of multimodal generative AI models. It's designed to be highly versatile, capable of handling text, images, and potentially other modalities in the future.</p> <ul> <li>Multimodal: Gemini is designed to handle not just text, but also images and potentially other modalities like audio and video in the future. This allows for richer and more nuanced interactions compared to text-only models.</li> <li>Family of Models: Gemini is not a single model, but a family of models with different sizes and capabilities. This allows developers to choose the model that best suits their needs and resource constraints.</li> <li>Advanced Reasoning and Coding:  Gemini is expected to demonstrate improved capabilities in areas like reasoning, coding, and complex problem-solving.</li> <li>Integration with Google Products: Gemini is integrated into various Google products such as Google Workspace (e.g. Docs, Slides, Sheets), Google Cloud Platform, and NotebookLM.</li> </ul> <p>Please see the documentation page for further details.</p> <p>Within AI Studio, you can access Gemini in two ways:</p> <ul> <li>Web Service: This provides a user-friendly interface for interacting with Gemini using natural language prompts.</li> <li>API Access: For more advanced use cases, you can access Gemini programmatically using its API (Application Programming Interface). This allows you to integrate Gemini into your own applications or workflows. See the Google Gemini cookbook repository for code samples in Jupyter Notebook format. Many of the sample notebooks can be opened in Google Colab with minimal effort. </li> </ul> <p>3.3 Concise Overview of the Gemini API</p> <p>The Gemini API allows you to interact with Gemini programmatically, giving you more control and flexibility compared to using the web interface.  You'll be using the <code>google-generativeai</code> Python package, which provides convenient functions for making API calls.</p> <p>Key Concepts</p> <ul> <li>API Key:  To access the API, you'll need an API key, which is a unique identifier that authenticates your requests. You can obtain an API key through the Google AI Studio console (The link with a key shaped icon on the left side navigation menu).</li> </ul> <p>Protect API Key!</p> <p>API key is like a password. Keep it safe. Do not accidentally share the password. Use environment variables or Colab Secrets to keep the API key safe.  See this notebook for details </p> <ul> <li> <p>Models:  Gemini offers a family of models with different capabilities. You'll specify the desired model in your API requests.</p> </li> <li> <p>Methods:  The API provides various methods for different tasks, such as generating text, translating languages, and answering questions.</p> </li> <li>Parameters:  You can customize the API's behavior using parameters, such as temperature and top-k, which we discussed in the prompt design section.</li> </ul> <p>Basic Workflow</p> <p>Here's a simplified workflow for using the Gemini API with the <code>google-generativeai</code> package:</p> <ol> <li>Install the package: <code>pip install google-generativeai</code></li> <li>Import the library: <code>import google.generativeai as genai</code></li> <li>Set your API key: <code>genai.configure(api_key='YOUR_API_KEY')</code></li> <li>Create a model instance: <code>model = genai.GenerativeModel('gemini-pro')</code> (or another model name)</li> <li>Generate text: <code>response = model.generate_text(prompt='Your prompt here')</code></li> <li>Access the output: <code>print(response.result)</code></li> </ol> <p>See this API reference for text generation code snippets.</p> <p>3.5 Hands-on Prompt Creation</p> <p>Now, let's put your prompt design skills to the test! Within AI Studio, you can experiment with various types of prompts:</p> <ul> <li>System Instructions: Provide high-level guidance to the LLM, such as setting its persona or defining constraints.</li> <li>Few-shot Examples: Give the LLM a few examples of the desired output to guide its generation process.</li> <li>Role-play: Ask the LLM to assume a specific role or scenario to generate contextually relevant responses.</li> </ul> <p>Here is an example to get you started. Explore more prompting strategies sample here.</p> <pre><code>!pip install -U -q \"google-generativeai&gt;=0.7.2\"\nimport google.generativeai as genai\n\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nmodel = genai.GenerativeModel(\n    \"models/gemini-1.5-flash\",\n    system_instruction=\"\"\"\n    You are a business school professor teaching a course on computational thinking for business students with limited prior programming experience. You are an expert in generative AI. You provide crisp explanations of technical concepts with relatable examples.\n    You will enquire about and confirm the information you need about students' prior knowledge before explaining advanced technical concepts\n    \"\"\",\n)\nresponse = model.generate_content(\n    \"Explain how AI works\",\n    generation_config = genai.GenerationConfig(\n        max_output_tokens=1000,\n        temperature=0.1,\n    )\n)\n\nfrom IPython.display import display, Markdown\ndisplay(Markdown(response.text))\n</code></pre> Annotated version of code <pre><code># Install the google-generativeai package. The -U flag updates to the latest version, \n# and -q flag ensures quiet installation (minimal output).\n!pip install -U -q \"google-generativeai&gt;=0.7.2\" \n\n# Import the library for using Google's generative AI models.\nimport google.generativeai as genai\n\n# Import the userdata module to access user-specific data stored in Colab.\nfrom google.colab import userdata\n\n# Retrieve the Google API key from user data. This key is needed to authenticate API requests.\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n\n# Configure the generative AI library with the API key.\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# Create a GenerativeModel instance using the specified Gemini model (\"gemini-1.5-flash\").\nmodel = genai.GenerativeModel(\n    \"models/gemini-1.5-flash\",\n    # Provide a system instruction to guide the model's behavior and persona.\n    system_instruction=\"\"\"\n    You are a business school professor teaching a course on computational thinking for business students with limited prior programming experience. You are an expert in generative AI. You provide crisp explanations of technical concepts with relatable examples.\n    You will enquire about and confirm the information you need about students' prior knowledge before explaining advanced technical concepts\n    \"\"\",\n)\n\n# Generate content from the model using the provided prompt and generation configuration.\nresponse = model.generate_content(\n    \"Explain how AI works\",\n    # Configure the generation parameters, such as the maximum number of output tokens and temperature.\n    generation_config = genai.GenerationConfig(\n        max_output_tokens=1000,\n        temperature=0.1,\n    )\n)\n\n# Import necessary modules for displaying the output in a Markdown format.\nfrom IPython.display import display, Markdown\n\n# Display the generated text from the model's response in a Markdown format.\ndisplay(Markdown(response.text))\n</code></pre> <p>By combining the user-friendly interface of AI Studio with the flexibility of the Gemini API, you can explore the full potential of generative AI and apply it to various business challenges.</p>"},{"location":"genai/#references","title":"References:","text":"<ul> <li>Gemini API Reference</li> <li>Gemini Model Card</li> <li>Hugging Face Models</li> <li>Gemini Prompting Strategies</li> </ul>"},{"location":"turtles/","title":"Computational Thinking with Turtles","text":"<p>In today's technology-driven world, computational thinking is an essential skill for effective leadership, even without requiring you to become a programmer. This lesson demystifies computational thinking, presenting it as a powerful problem-solving framework applicable to various business challenges.</p> <p>Learning Objectives:</p> <p>By the end of this lesson, you will be able to:</p> <ul> <li>Define computational thinking and its core concepts: decomposition, abstraction, algorithmic thinking, and pattern recognition.</li> <li>Relate these concepts to familiar business practices and scenarios.</li> <li>Apply computational thinking to analyze and solve a problem using a simple coding exercise.</li> <li>Understand the importance of refactoring and iterative development in creating effective solutions.</li> <li>Appreciate the role of computational thinking in user experience design and product development.</li> </ul> <p>Lesson Overview:</p> <ol> <li>Introduction to Computational Thinking: We'll define computational thinking and explore its core concepts, providing relatable examples from the business world.</li> <li>Connecting to Familiar Concepts: You'll engage in a critical thinking exercise to connect computational thinking to your own professional experiences.</li> <li>Introducing the Turtle Problem:  We'll introduce a visual coding exercise using Turtle Graphics to demonstrate the practical application of computational thinking.</li> <li>Refactoring and Applying Concepts:  We'll iteratively refactor the code, highlighting how each step aligns with the principles of computational thinking.</li> <li>Complete Code and Wrap-up: We'll present the final refactored code, emphasizing the key takeaways and the broader relevance of computational thinking for business leaders.</li> </ol> <p>This lesson provides a practical and engaging introduction to computational thinking, empowering you to apply these valuable skills in your everyday work and strategic decision-making.</p>"},{"location":"turtles/#introduction-to-computational-thinking","title":"Introduction to Computational Thinking","text":"<p>In today's rapidly evolving digital landscape, business leaders need to be equipped with more than just traditional management skills.  Computational thinking, a problem-solving methodology rooted in computer science principles, is becoming increasingly crucial for effective decision-making and navigating the complexities of the modern business world.</p> <p>While the term may seem intimidating to those without a technical background, computational thinking is not about coding. It's a mental framework applicable to various challenges, empowering you to approach problems with greater clarity and efficiency.</p> <p>This approach involves four key concepts:</p> <ul> <li> <p>Decomposition:  Consider the process of developing a strategic plan. It would be overwhelming to tackle the entire plan as a single entity. Instead, you would decompose it into smaller, more manageable components, such as market analysis, competitor analysis, and internal resource assessment. This is the essence of decomposition \u2013 breaking down complex problems into smaller, more manageable parts.</p> </li> <li> <p>Abstraction:  An organization chart provides a high-level view of a company's structure, highlighting key roles and reporting relationships without delving into the specifics of each employee's responsibilities. This is abstraction in action \u2013 focusing on essential information while filtering out irrelevant details. Financial reports similarly use abstraction to present key performance indicators.</p> </li> <li> <p>Algorithmic Thinking:  Standard Operating Procedures (SOPs) are a prime example of algorithmic thinking in a business context. They outline a precise sequence of steps to ensure consistency and efficiency in executing tasks.  Essentially, algorithmic thinking involves defining a step-by-step process to achieve a desired outcome.</p> </li> <li> <p>Pattern Recognition:  Analyzing sales data to identify seasonal trends is a common application of pattern recognition in business. By identifying recurring patterns or trends, you can make more informed decisions about inventory management, marketing campaigns, and other strategic initiatives. Market research relies heavily on pattern recognition to understand consumer behavior.</p> </li> </ul> <p>By mastering these concepts, you can enhance your problem-solving abilities, even without writing any code. Computational thinking helps you:</p> <ul> <li>Analyze problems systematically</li> <li>Identify core issues</li> <li>Develop effective solutions</li> <li>Communicate solutions clearly and concisely</li> </ul> <p>In the following sections, we will delve deeper into each of these concepts, exploring their practical applications in various business scenarios.</p>"},{"location":"turtles/#connecting-to-familiar-concepts","title":"Connecting to Familiar Concepts","text":"<p>Critical Thinking Exercise:</p> <p>Now that you've been introduced to the four pillars of computational thinking \u2013 decomposition, abstraction, algorithmic thinking, and pattern recognition \u2013 let's explore how these concepts connect to your existing knowledge and experience in the business world.</p> <p>Instructions:</p> <ol> <li>Reflect: Take a moment to consider your typical work tasks and responsibilities.</li> <li>Analyze:  Identify specific instances where you have already applied elements of computational thinking, even without realizing it.</li> <li>Document:  For each of the four concepts, write down at least one concrete example from your professional experience that demonstrates its application.</li> </ol> <p>Tips for Success:</p> <ul> <li>Think broadly: Computational thinking isn't limited to technology-related tasks. Consider how you approach problem-solving, decision-making, and process optimization in general.</li> <li>Be specific:  Instead of general statements, provide detailed examples with context.</li> <li>Consider different aspects of your work:  Think about strategic planning, project management, data analysis, communication, and even routine tasks.</li> </ul> <p>Example:</p> <p>Let's say you're responsible for launching a new product. Here's how you might apply computational thinking:</p> <ul> <li>Decomposition: Break down the launch into smaller phases (market research, product development, marketing campaign, sales strategy, etc.).</li> <li>Abstraction:  Create a high-level timeline or Gantt chart that focuses on key milestones without getting bogged down in every minor detail.</li> <li>Algorithmic Thinking: Develop a checklist or workflow for the launch process to ensure consistency and efficiency.</li> <li>Pattern Recognition: Analyze data from previous product launches to identify successful strategies and potential pitfalls.</li> </ul> <p>By completing this exercise, you'll gain a deeper understanding of how computational thinking is already embedded in many business practices. This awareness will help you consciously apply these concepts to become a more effective and efficient leader.</p>"},{"location":"turtles/#introducing-the-turtle-problem","title":"Introducing the Turtle Problem","text":"<p>In this section, we'll transition from theory to practice. We'll use a simple programming environment called \"Turtle Graphics\" to illustrate how computational thinking can be applied to create something visual and dynamic.</p> <p>Source</p> <p>The original code comes from the GitHub repository of the ColabTurtlePlus. The repository contains excellent set of examples that can be analyzed and extended for challenge assignment for Module 1. Make sure to reference the code you use for the assignment.</p> <p></p> <p>Now, let's take a look at the code that generates these patterns:</p> <pre><code>from ColabTurtlePlus.Turtle import *\nclearscreen()\nsetup(500,300)\nT = Turtle()\nT.color('red', 'yellow')\nT.speed(13)\nT.width(1.5)\nS = T.clone()\nT.fillrule(\"evenodd\")\nS.fillrule(\"nonzero\")\nx0 = -225\nT.jumpto(x0,0)\nS.jumpto(25,0)\nT.begin_fill()\nS.begin_fill()\nwhile True:\n    T.forward(200)\n    T.left(170)\n    S.forward(200)\n    S.left(170)\n    if (T.getx()-x0)**2 + T.gety()**2 &lt; 1:\n        break\nT.end_fill()\nS.end_fill()\n</code></pre> Annotated version of the code <pre><code># Import the necessary library for turtle graphics.\nfrom ColabTurtlePlus.Turtle import *\n\n# Clear the screen to start fresh.\nclearscreen()\n\n# Set up the drawing area with a width of 500 pixels and a height of 300 pixels.\nsetup(500,300)\n\n# Create a turtle object and name it 'T'. This is like your pen for drawing.\nT = Turtle()\n\n# Set the turtle's color. The first color is for the line, the second for filling shapes.\nT.color('red', 'yellow')\n\n# Set the turtle's drawing speed. 13 is quite fast.\nT.speed(13)\n\n# Set the width of the line the turtle draws.\nT.width(1.5)\n\n# Create a clone of the first turtle, named 'S'. Now we have two 'pens'!\nS = T.clone()\n\n# This determines how overlapping shapes are filled. \n# \"evenodd\" means areas overlapped an odd number of times are filled, \n# \"nonzero\" means any overlapped area is filled.\nT.fillrule(\"evenodd\")\nS.fillrule(\"nonzero\")\n\n# Set a starting x-coordinate.\nx0 = -225\n\n# Move the turtles to their starting positions without drawing a line.\nT.jumpto(x0,0)\nS.jumpto(25,0)\n\n# Start filling the shapes the turtles are about to draw.\nT.begin_fill()\nS.begin_fill()\n\n# This loop makes the turtles draw until a condition is met.\nwhile True:\n    # Move the turtle 'T' forward 200 pixels.\n    T.forward(200)\n    # Turn the turtle 'T' left by 170 degrees.\n    T.left(170)\n    # Move the turtle 'S' forward 200 pixels.\n    S.forward(200)\n    # Turn the turtle 'S' left by 170 degrees.\n    S.left(170)\n    # This checks if the turtle 'T' is back near its starting point. \n    # It uses a bit of math (Pythagorean theorem) to calculate the distance.\n    if (T.getx()-x0)**2 + T.gety()**2 &lt; 1:\n        # If the turtle is close enough, exit the loop.\n        break\n\n# Stop filling the shapes.\nT.end_fill()\nS.end_fill()\n</code></pre> <p>Don't worry if it looks like gibberish right now! We'll break it down step-by-step in the following sections. </p> <p>The Challenge:</p> <p>Your challenge is to understand this code and then modify it to create your own unique patterns. This will involve applying the concepts of computational thinking we've discussed:</p> <ul> <li>Decomposition: How can you break down this code into smaller, more manageable parts?</li> </ul> Click to reveal answer <p>You can decompose this code by identifying distinct blocks of functionality:</p> <ul> <li>Setup: The lines that import the library, clear the screen, and set up the drawing area (<code>from ColabTurtlePlus...</code>, <code>clearscreen()</code>, <code>setup()</code>).</li> <li>Turtle Initialization: The lines that create the turtle objects and set their properties (<code>T = Turtle()</code>, <code>T.color()</code>, <code>T.speed()</code>, etc.).</li> <li>Movement and Drawing: The <code>while True</code> loop that contains the instructions for the turtles to move and turn.</li> <li>Filling: The lines that start and end the filling of the shapes (<code>T.begin_fill()</code>, <code>T.end_fill()</code>).</li> </ul> <p>By separating these parts, you can focus on understanding and modifying each piece individually.</p> <ul> <li>Abstraction: Can you identify any elements that are abstracted away or hidden from the user?</li> </ul> Click to reveal answer <p>Yes, several elements are abstracted in this code:</p> <ul> <li>Turtle commands: Commands like <code>forward()</code>, <code>left()</code>, and <code>jumpto()</code> abstract away the complex mathematics involved in moving and drawing on the screen. You don't need to know trigonometry or geometry to use them.</li> <li>Library functions: The functions provided by the <code>ColabTurtlePlus.Turtle</code> library abstract away the lower-level code that interacts with the computer's graphics system.</li> <li>Fill rule: The <code>fillrule</code> option abstracts the complexities of how overlapping shapes are filled.</li> </ul> <p>Abstraction simplifies the code, allowing you to focus on the desired outcome without getting bogged down in the underlying implementation details.</p> <ul> <li>Algorithmic Thinking: What is the core algorithm that generates the pattern?</li> </ul> Click to reveal answer <p>The core algorithm is within the <code>while True</code> loop:</p> <ol> <li>Move the turtle forward by a certain distance (<code>T.forward(200)</code>).</li> <li>Turn the turtle left by a certain angle (<code>T.left(170)</code>).</li> <li>Repeat these steps until the turtle returns to its starting position.</li> </ol> <p>This simple algorithm, when executed repeatedly, generates the complex spiral patterns.</p> <ul> <li>Pattern Recognition: Can you identify any patterns in the code itself, and how do those patterns translate into the visual output?</li> </ul> Click to reveal answer <p>The most obvious pattern is the repetition of the <code>forward()</code> and <code>left()</code> commands within the loop. This repetition creates the spiral shape.</p> <p>The specific values used for distance and angle determine the tightness and overall form of the spiral. Experimenting with these values will result in different visual patterns.</p> <p>By recognizing these patterns in the code, you can predict how changes to the code will affect the visual output.</p>"},{"location":"turtles/#refactoring-and-applying-concepts","title":"Refactoring and Applying Concepts","text":"<p>Now it's time to roll up our sleeves and get hands-on with the code! We'll take the turtle graphics program and refactor it step-by-step. Remember that refactoring simply means improving the code's structure and readability without changing its functionality.  In the real world, code is rarely perfect from the start. We engage in continuous development, iteratively refining and improving it. Sometimes, the areas that need improvement aren't obvious. Just as in business, we experiment with changes and rely on data to guide our decisions. A/B testing helps us understand user preferences for user-facing changes, while performance testing guides optimizations for speed and efficiency. With each iteration, we'll see how computational thinking principles guide our refactoring decisions.</p> <p>Iteration 1: Identifying the Algorithm</p> <p>Let's revisit the code:</p> <pre><code>from ColabTurtlePlus.Turtle import *\nclearscreen()\nsetup(500,300)\nT = Turtle()\nT.color('red', 'yellow')\nT.speed(13)\nT.width(1.5)\nS = T.clone()\nT.fillrule(\"evenodd\")\nS.fillrule(\"nonzero\")\nx0 = -225\nT.jumpto(x0,0)\nS.jumpto(25,0)\nT.begin_fill()\nS.begin_fill()\nwhile True:\n    T.forward(200)\n    T.left(170)\n    S.forward(200)\n    S.left(170)\n    if (T.getx()-x0)**2 + T.gety()**2 &lt; 1:\n        break\nT.end_fill()\nS.end_fill()\n</code></pre> <p>Can you spot the core algorithm that generates the spiral pattern?</p> Click to reveal answer <p>It's the <code>while True</code> loop! This loop repeatedly instructs the turtles to move forward and turn left, creating the spiral shape.</p> <pre><code>while True:\n      T.forward(200)\n      T.left(170)\n      S.forward(200)\n      S.left(170)\n      if (T.getx()-x0)**2 + T.gety()**2 &lt; 1:\n          break\n  </code></pre> <p>This is algorithmic thinking in action - defining a precise sequence of steps to achieve a desired outcome.</p> <p>Iteration 2: Abstraction with a Function</p> <p>To make the code more organized and reusable, let's encapsulate this algorithm within a function:</p> <pre><code>def draw_spiral(turtle_obj, step_size, angle):\n  x0 = turtle_obj.getx()\n  turtle_obj.begin_fill()\n  while True:\n      turtle_obj.forward(step_size)\n      turtle_obj.left(angle)\n      if (turtle_obj.getx() - x0)**2 + turtle_obj.gety()**2 &lt; 1:\n          break\n  turtle_obj.end_fill()\n\n# Now you can use the function like this:\ndraw_spiral(T, 200, 170)  # For turtle T\ndraw_spiral(S, 200, 170)  # For turtle S \n</code></pre> <p>What have we achieved here?</p> Click to reveal answer <p>We've created an abstraction! The <code>draw_spiral()</code> function hides the complexity of the algorithm. Now, someone using this function doesn't need to understand the details of the loop or the math involved. They can simply call the function with the desired parameters: the turtle object, step size, and angle.</p> <p>This is similar to using a function in a spreadsheet software. You don't need to know the formula behind <code>SUM()</code> or <code>AVERAGE()</code>, you just need to know what inputs it requires.</p> <p>Iteration 3: Abstraction and Progressive Disclosure with Default Arguments</p> <p>In the previous iteration, we abstracted the spiral drawing logic into a function. Now, let's further simplify the code by creating a function to set up our turtles:</p> <pre><code>def create_turtle(color1='red', color2='yellow', speed=13, width=1.5, fillrule=\"evenodd\"):\n  \"\"\"\n  Creates a turtle object with specified properties.\n\n  Args:\n    color1: The color of the turtle's pen.\n    color2: The fill color of the turtle.\n    speed: The drawing speed of the turtle.\n    width: The width of the turtle's pen.\n    fillrule: The fill rule for the turtle.\n\n  Returns:\n    A Turtle object with the specified properties.\n  \"\"\"\n  T = Turtle()\n  T.color(color1, color2)\n  T.speed(speed)\n  T.width(width)\n  T.fillrule(fillrule)\n  return T\n\n# Now you can create turtles like this:\nT1 = create_turtle()  # Uses all default values\nT2 = create_turtle('blue', 'green', fillrule=\"nonzero\")  # Overrides some defaults\n</code></pre> <p>Notice how we've provided default values for all the arguments in the <code>create_turtle()</code> function. This allows users to create a turtle with the standard settings by simply calling the function without any arguments (<code>T1 = create_turtle()</code>).  However, if they need to customize the turtle's properties, they can provide specific values for any of the arguments, like we did for <code>T2</code>.</p> <p>This demonstrates two important concepts:</p> <ul> <li>Abstraction:  The function hides the details of creating and configuring a turtle object, making the code cleaner and easier to use.</li> <li>Progressive Disclosure:  By providing default values, we simplify the initial interaction for users. They don't need to be overwhelmed with all the possible options right away. They can start with the defaults and then progressively explore more advanced customizations as needed.</li> </ul> <p>This principle of progressive disclosure is widely used in software design. Think about the settings menu on your phone. The most commonly used settings are readily accessible, while more advanced options are tucked away in submenus. This makes the user experience less daunting and more efficient.</p> <p>By using default arguments in our code, we're applying the same principle, making it easier for others (or even our future selves) to use and understand our code.</p> <p>Iteration 4: Decomposition for Clarity</p> <p>Let's break down the setup and drawing actions into separate functions:</p> <pre><code>def create_turtle(color1='red', color2='yellow', speed=13, width=1.5, fillrule=\"evenodd\"):\n  \"\"\"Creates a turtle object with specified properties.\"\"\"\n  T = Turtle()\n  T.color(color1, color2)\n  T.speed(speed)\n  T.width(width)\n  T.fillrule(fillrule)\n  return T\n\ndef draw_spirals(turtle1, turtle2, step_size, angle):\n  \"\"\"Sets up two turtles and draws spirals with them.\"\"\"\n  x0 = -225  # Set a starting x-coordinate\n  turtle1.jumpto(x0, 0)\n  turtle2.jumpto(25, 0)\n  draw_spiral(turtle1, step_size, angle)\n  draw_spiral(turtle2, step_size, angle)\n\n# Now the main part of the program becomes very concise:\nclearscreen()\nsetup(500, 300)\n\nT1 = create_turtle()\nT2 = create_turtle('blue', 'green', fillrule=\"nonzero\")\n\ndraw_spirals(T1, T2, 200, 170) \n</code></pre> <p>By decomposing the code into these functions, we've made it:</p> <ul> <li>More Modular: Each function performs a specific task, making the code easier to understand and maintain.</li> <li>More Reusable:  The <code>create_turtle()</code> function can be used to create turtles with different properties throughout the program.</li> <li>More Readable: The main part of the program now clearly shows the high-level steps: create turtles, draw spirals.</li> </ul> <p>This refactoring highlights how decomposition can be used to organize and simplify complex tasks, a principle that applies not only to coding but also to various business processes.  It also shows how breaking down a problem into smaller parts can make it easier to manage and solve, a key aspect of computational thinking.</p> <p>Iteration 5: Data Structuring and Tuple Unpacking</p> <p>Let's say we want to draw two spirals with different properties (step size and angle). We can group the relevant data for each spiral using tuples.</p> <pre><code>def create_turtle(color1='red', color2='yellow', speed=13, width=1.5, fillrule=\"evenodd\"):\n  \"\"\"Creates a turtle object with specified properties.\"\"\"\n  T = Turtle()\n  T.color(color1, color2)\n  T.speed(speed)\n  T.width(width)\n  T.fillrule(fillrule)\n  return T\n\ndef draw_spirals(turtle1_data, turtle2_data):\n  \"\"\"Sets up two turtles and draws spirals with them.\"\"\"\n  x0 = -225  # Set a starting x-coordinate\n  turtle1, step_size1, angle1 = turtle1_data  # Unpack the tuple\n  turtle2, step_size2, angle2 = turtle2_data  # Unpack the tuple\n  turtle1.jumpto(x0, 0)\n  turtle2.jumpto(25, 0)\n  draw_spiral(turtle1, step_size1, angle1)  # Call with unpacked values\n  draw_spiral(turtle2, step_size2, angle2)  # Call with unpacked values\n\ndef draw_spiral(turtle_obj, step_size, angle):\n  \"\"\"Draws a spiral with the given turtle object.\"\"\"\n  x0 = turtle_obj.getx()\n  turtle_obj.begin_fill()\n  while True:\n      turtle_obj.forward(step_size)\n      turtle_obj.left(angle)\n      if (turtle_obj.getx() - x0)**2 + turtle_obj.gety()**2 &lt; 1:\n          break\n  turtle_obj.end_fill()\n\n# Now the main part of the program:\nclearscreen()\nsetup(500, 300)\n\nT1 = create_turtle()\nT2 = create_turtle('blue', 'green', fillrule=\"nonzero\")\n\n# Create tuples to store turtle data\nturtle1_data = (T1, 200, 170)  \nturtle2_data = (T2, 150, 120)  \n\ndraw_spirals(turtle1_data, turtle2_data)\n</code></pre> <ul> <li>We create tuples (<code>turtle1_data</code>, <code>turtle2_data</code>) to store the turtle object, step size, and angle together. This helps organize related data.</li> <li>In <code>draw_spirals</code>, we use tuple unpacking to assign the individual elements of the tuples to separate variables.</li> <li>When calling <code>draw_spiral</code>, we pass these unpacked values as arguments.</li> </ul> <p>This demonstrates:</p> <ul> <li>Data Structuring: Using tuples to group related data.</li> <li>Tuple Unpacking:  A convenient way to access elements of a tuple.</li> <li>Decomposition:  The <code>draw_spirals</code> function now clearly decomposes the task of drawing two spirals with different properties by calling the <code>draw_spiral</code> function twice with different parameters.</li> </ul>"},{"location":"turtles/#complete-code-and-wrap-up","title":"Complete Code and Wrap-up","text":"<p>Throughout this lesson, we've explored the core concepts of computational thinking \u2013 decomposition, abstraction, algorithmic thinking, and pattern recognition \u2013 and applied them to refactor a simple turtle graphics program.  Let's take a look at the final version of the code:</p> <pre><code>from ColabTurtlePlus.Turtle import *\n\ndef create_turtle(color1='red', color2='yellow', speed=13, width=1.5, fillrule=\"evenodd\"):\n  \"\"\"Creates a turtle object with specified properties.\"\"\"\n  T = Turtle()\n  T.color(color1, color2)\n  T.speed(speed)\n  T.width(width)\n  T.fillrule(fillrule)\n  return T\n\ndef draw_spirals(turtle1_data, turtle2_data):\n  \"\"\"Sets up two turtles and draws spirals with them.\"\"\"\n  x0 = -225  # Set a starting x-coordinate\n  turtle1, step_size1, angle1 = turtle1_data  # Unpack the tuple\n  turtle2, step_size2, angle2 = turtle2_data  # Unpack the tuple\n  turtle1.jumpto(x0, 0)\n  turtle2.jumpto(25, 0)\n  draw_spiral(turtle1, step_size1, angle1)  # Call with unpacked values\n  draw_spiral(turtle2, step_size2, angle2)  # Call with unpacked values\n\ndef draw_spiral(turtle_obj, step_size, angle):\n  \"\"\"Draws a spiral with the given turtle object.\"\"\"\n  x0 = turtle_obj.getx()\n  turtle_obj.begin_fill()\n  while True:\n      turtle_obj.forward(step_size)\n      turtle_obj.left(angle)\n      if (turtle_obj.getx() - x0)**2 + turtle_obj.gety()**2 &lt; 1:\n          break\n  turtle_obj.end_fill()\n\n# Main part of the program:\nclearscreen()\nsetup(500, 300)\n\nT1 = create_turtle()\nT2 = create_turtle('blue', 'green', fillrule=\"nonzero\")\n\n# Create tuples to store turtle data\nturtle1_data = (T1, 200, 170)  \nturtle2_data = (T2, 150, 120)  \n\ndraw_spirals(turtle1_data, turtle2_data)\n</code></pre> <p>Lesson Colab Notebook</p> <p>The interactive notebook version of this code is available on the course GitHub Repository.</p> <p>Connecting to Foundational Concepts:</p> <ul> <li>Decomposition: We broke down the original code into smaller, more manageable functions (<code>create_turtle</code>, <code>draw_spirals</code>, <code>draw_spiral</code>). This made the code easier to understand, test, and modify.</li> <li>Abstraction: We used functions to hide the complexity of certain tasks, such as creating a turtle object and drawing a spiral. This allowed us to use these functions without needing to know the underlying details.</li> <li>Algorithmic Thinking: We defined a clear algorithm for drawing a spiral using a <code>while</code> loop and the <code>forward</code> and <code>left</code> commands.</li> <li>Pattern Recognition: We identified patterns in the code, such as the repetition of commands within the loop, and used this understanding to create different visual patterns. Pattern recognition extends beyond just identifying patterns in data or code. It also involves understanding user needs and behaviors to design more effective and user-friendly solutions. This is crucial in areas like UX design and product development.</li> </ul> <p>Key Takeaways:</p> <ul> <li>Computational thinking is a powerful problem-solving approach that can be applied to various domains, even without extensive coding experience.</li> <li>By understanding and applying concepts like decomposition, abstraction, algorithmic thinking, and pattern recognition, you can improve your problem-solving skills and approach challenges with greater clarity and efficiency.</li> <li>Even simple coding exercises, like the turtle graphics example, can provide valuable insights into the principles of computational thinking and their practical applications.</li> </ul> <p>This concludes the lesson on computational thinking with turtle graphics. We encourage you to experiment with the code, modify it to create your own patterns, and continue exploring the fascinating world of computational thinking!</p>"},{"location":"turtles/#references","title":"References","text":"<ul> <li>turtle - Python standard library package documentation</li> <li>ColabTurtlePlus - Python package for turtle graphics on Colab notebooks</li> <li>Turtle Star - Turtle star example from ColabTurtlePlus GitHub Repository.</li> <li>Exploring Computational Thinking - Google for Education course resources</li> <li>Introduction to Computational Thinking What is Computational Thinking?</li> </ul>"}]}